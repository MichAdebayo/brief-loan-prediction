{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ml/v613w2ns1z31hpn87j8vcl8h0000gq/T/ipykernel_29767/784972605.py:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"SBAnational.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"SBAnational.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of dataset\n",
    "wdf = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoanNr_ChkDgt          int64\n",
       "Name                  object\n",
       "City                  object\n",
       "State                 object\n",
       "Zip                    int64\n",
       "Bank                  object\n",
       "BankState             object\n",
       "NAICS                  int64\n",
       "ApprovalDate          object\n",
       "ApprovalFY            object\n",
       "Term                   int64\n",
       "NoEmp                  int64\n",
       "NewExist             float64\n",
       "CreateJob              int64\n",
       "RetainedJob            int64\n",
       "FranchiseCode          int64\n",
       "UrbanRural             int64\n",
       "RevLineCr             object\n",
       "LowDoc                object\n",
       "ChgOffDate            object\n",
       "DisbursementDate      object\n",
       "DisbursementGross     object\n",
       "BalanceGross          object\n",
       "MIS_Status            object\n",
       "ChgOffPrinGr          object\n",
       "GrAppv                object\n",
       "SBA_Appv              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "wdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View missing values matrix\n",
    "msno.matrix(wdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoanNr_ChkDgt             0\n",
       "Name                     14\n",
       "City                     30\n",
       "State                    14\n",
       "Zip                       0\n",
       "Bank                   1559\n",
       "BankState              1566\n",
       "NAICS                     0\n",
       "ApprovalDate              0\n",
       "ApprovalFY                0\n",
       "Term                      0\n",
       "NoEmp                     0\n",
       "NewExist                136\n",
       "CreateJob                 0\n",
       "RetainedJob               0\n",
       "FranchiseCode             0\n",
       "UrbanRural                0\n",
       "RevLineCr              4528\n",
       "LowDoc                 2582\n",
       "ChgOffDate           736465\n",
       "DisbursementDate       2368\n",
       "DisbursementGross         0\n",
       "BalanceGross              0\n",
       "MIS_Status             1997\n",
       "ChgOffPrinGr              0\n",
       "GrAppv                    0\n",
       "SBA_Appv                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View columns (and the number of rows) with missing values\n",
    "wdf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String and Numerical Data manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert columns with monetary values to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns with monetary values to integers by removing decimal places and dollar signs\n",
    "# to standardize the format and optimize storage for calculations.\n",
    "\n",
    "list_monetary_integers = ['DisbursementGross', 'GrAppv', 'BalanceGross', 'SBA_Appv', 'ChgOffPrinGr']\n",
    "\n",
    "wdf[list_monetary_integers] = round(wdf[list_monetary_integers].replace(r'[$, ]', '', regex=True).astype(float).astype(int), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values without \"Y\" or \"N\" with NA\n",
    "wdf['LowDoc'] = wdf['LowDoc'].replace(r'[0CSAR1]',np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'City' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rows with missing city data\n",
    "check_missing_city = wdf[wdf['City'].isna()]\n",
    "\n",
    "# check_missing_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to input city data based on zip code\n",
    "zip_city = [84109, 70130, 60624, 60636, \n",
    "            92102, 44115, 63103, 63105, \n",
    "            63013, 98104, 50309, 78204, \n",
    "            64106,  2169,  2108,  2401,  \n",
    "            2165, 40209, 28402, 48502]\n",
    "\n",
    "city_code = ['SALT LAKE CITY', 'NEW ORLEANS', 'CHICAGO', 'CHICAGO', \n",
    "             'SAN DIEGO', 'CLEVELAND', 'ST. LOUIS', 'ST. LOUIS', \n",
    "             'BEAUFORT', 'SEATTLE', 'DES MOINES', 'SAN ANTONIO',\n",
    "             'KANSAS CITY', 'BOSTON', 'BOSTON', 'FALL RIVER',\n",
    "             'BOSTON', 'LOUISVILLE', 'WILMINGTON', 'FLINT']\n",
    "\n",
    "# Create a dictionary to map zip code to city\n",
    "zip_city_dict = dict(zip(zip_city, city_code))\n",
    "\n",
    "# Input city data based on zip code\n",
    "for key, value in zip_city_dict.items():\n",
    "    wdf.loc[(wdf['Zip'] == key) & (wdf['City'].isna()), 'City'] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'State' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to input state data based on zip code (state for zip code with O value is determined by its city)\n",
    "state_zipcode = [8070, 0, 95682, 96205, 67219, \n",
    "                79925, 33410, 54205, 54025, \n",
    "                84124, 65049, 75236, 76052, \n",
    "                76645]\n",
    "\n",
    "state_code = ['NJ', 'NY', 'CA', 'CA', 'KS',\n",
    "              'TX', 'FL', 'WI', 'WI',\n",
    "              'UT', 'MO', 'TX', 'TX',\n",
    "              'TX']\n",
    "\n",
    "# Create a dictionary to map city name to state\n",
    "state_city_dict = dict(zip(state_zipcode, state_code))\n",
    "\n",
    "# Input state data based on city name\n",
    "for key, value in state_city_dict.items():\n",
    "    wdf.loc[(wdf['Zip'] == key) & (wdf['State'].isna()), 'State'] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'NewExist' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input NaN for rows with missing NewExist data\n",
    "wdf['NewExist'] = wdf['NewExist'].replace({0.0: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'RevLineCr' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input NaN for rows with \"other\" values in the RevLineCr' data\n",
    "wdf['RevLineCr'] = wdf['RevLineCr'].replace(r'[0T1R`2C,37A5.4Q\\-]', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Clean by 'LowDoc' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update only NaN values in LowDoc based on GrAppv\n",
    "wdf[\"LowDoc\"] = wdf.apply(lambda row: \"Y\" if pd.isna(row[\"LowDoc\"]) and row[\"GrAppv\"] <= 150000 else \"N\" if pd.isna(row[\"LowDoc\"]) else row[\"LowDoc\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'UrbanRural' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input NaN for rows with missing UrbanRural data\n",
    "wdf['UrbanRural'] = wdf['UrbanRural'].replace({0: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'MIS_STATUS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces in 'MIS_STATUS' column\n",
    "wdf['MIS_Status'] = wdf['MIS_Status'].apply(lambda x: str(x).replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relace nans with NaNs\n",
    "wdf['MIS_Status'] = np.where(wdf['MIS_Status'] == \"nan\", np.nan, wdf['MIS_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update missing values based on 'ChgOffDate' column\n",
    "wdf.loc[\n",
    "    wdf['MIS_Status'].isna() & wdf['ChgOffDate'].notna(), \n",
    "    'MIS_Status'\n",
    "] = \"CHGOFF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean by 'ChgOffDate' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'ChgOffDate' with a default date '01-Jan-1970' if missing\n",
    "wdf['ChgOffDate'] = np.where(wdf['ChgOffDate'].isna(), pd.to_datetime('01-Jan-1970', format='%d-%b-%Y'), wdf['ChgOffDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map NAICS code to actvity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first two digits of the NAICS code\n",
    "wdf['NAICS_class_code'] = wdf['NAICS'].apply(lambda x: int(str(x)[:2]) if pd.notna(x) and len(str(x)) >= 2 else 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map NAICS code to industry\n",
    "wdf['Industry'] = wdf['NAICS_class_code'].map({\n",
    "    11: \"Agriculture, forestry, fishing and hunting\",\n",
    "    21: \"Mining, Quarrying, and oil and gas extraction\",\n",
    "    22: \"Utilities\",\n",
    "    23: \"Construction\",\n",
    "    31: \"Manufacturing\",\n",
    "    32: \"Manufacturing\",\n",
    "    33: \"Manufacturing\",\n",
    "    42: \"Wholesale trade\",\n",
    "    44: \"Retail trade\",\n",
    "    45: \"Retail trade\",\n",
    "    48: \"Transportation and warehousing\",\n",
    "    49: \"Transportation and warehousing\",\n",
    "    51: \"Information\",\n",
    "    52: \"Finance and insurance\",\n",
    "    53: \"Real estate and rental and leasing\",\n",
    "    54: \"Professional, scientific, and technical services\",\n",
    "    55: \"Management of companies and enterprises\",\n",
    "    56: \"Administrative and support and waste management and remediation services\",\n",
    "    61: \"Educational services\",\n",
    "    62: \"Health care and social assistance\",\n",
    "    71: \"Arts, enternaiment, and recreation\",\n",
    "    72: \"Accommodation and food services\",\n",
    "    81: \"Other services\", \n",
    "    92: \"Public administration\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode FranchiseCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'FranchiseCode' to binary values\n",
    "wdf['FranchiseCode_Encoded'] = wdf['FranchiseCode'].apply(lambda x: 'Yes' if x > 1 else 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add Real Estate Backed Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Term' to binary values\n",
    "wdf['RealEstate_Backed'] = wdf['Term'].apply(lambda x: \"Yes\" if x >= 240 else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Convert Date columns to DateTime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ml/v613w2ns1z31hpn87j8vcl8h0000gq/T/ipykernel_29767/1911448850.py:1: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  wdf['ApprovalDate'] = pd.to_datetime(wdf['ApprovalDate'], errors='ignore', format='%d-%b-%y')\n",
      "/var/folders/ml/v613w2ns1z31hpn87j8vcl8h0000gq/T/ipykernel_29767/1911448850.py:2: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  wdf['ChgOffDate'] = pd.to_datetime(wdf['ChgOffDate'], errors='ignore', format='%d-%b-%y')\n"
     ]
    }
   ],
   "source": [
    "wdf['ApprovalDate'] = pd.to_datetime(wdf['ApprovalDate'], errors='ignore', format='%d-%b-%y')\n",
    "wdf['ChgOffDate'] = pd.to_datetime(wdf['ChgOffDate'], errors='ignore', format='%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from 'ApprovalDate' and 'ChgOffDate' columns\n",
    "wdf['ApprovalDateYear'] = wdf['ApprovalDate'].dt.year\n",
    "wdf['ChgOffDateYear'] = wdf['ChgOffDate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month from 'ApprovalDate' columns\n",
    "wdf['ApprovalDateMonth'] = wdf['ApprovalDate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ApprovalFY' to string\n",
    "wdf['ApprovalFY'] = wdf['ApprovalFY'].apply(lambda x: str(x).strip()[:4])\n",
    "\n",
    "# Convert 'ApprovalFY' to datetime format\n",
    "wdf['ApprovalFY'] = pd.to_datetime(wdf['ApprovalFY'], errors='raise', format='mixed')\n",
    "\n",
    "# Extract year from 'ApprovalFY' column\n",
    "wdf['ApprovalFY'] = wdf['ApprovalFY'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ml/v613w2ns1z31hpn87j8vcl8h0000gq/T/ipykernel_29767/1024855919.py:5: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  wdf['DisbursementDate'] = pd.to_datetime(wdf['DisbursementDate'], errors='ignore',format='%d-%b-%y')\n"
     ]
    }
   ],
   "source": [
    "# Remove spaces in 'DisbursementDate' column\n",
    "wdf['DisbursementDate'] = wdf['DisbursementDate'].apply(lambda x: str(x).strip())\n",
    "\n",
    "# Convert 'DisbursementDate' to datetime format\n",
    "wdf['DisbursementDate'] = pd.to_datetime(wdf['DisbursementDate'], errors='ignore',format='%d-%b-%y')\n",
    "\n",
    "wdf['DisbursementDate'] =  wdf['DisbursementDate'].replace(np.nan, pd.to_datetime('01-Jan-1970', format='%d-%b-%Y'))\n",
    "\n",
    "wdf['DisbursementDateYear'] = wdf['DisbursementDate'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode 'State' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in 'State' column\n",
    "all_states = wdf['State'].unique()\n",
    "\n",
    "# Group states into regions\n",
    "northern_states_in_all_states = ['ME', 'NH', 'VT', 'MA', 'CT', 'RI', 'NY', 'PA', 'NJ', 'DE', 'MD', 'DC']\n",
    "western_satates_in_all_starts = ['WA', 'OR', 'CA', 'NV', 'ID', 'MT', 'WY', 'UT', 'CO', 'AZ', 'NM', 'AK', 'HI']\n",
    "eastern_states_in_all_states = ['ND', 'SD', 'NE', 'KS', 'MN', 'IA', 'MO', 'WI', 'IL', 'IN', 'MI', 'OH', 'KY', 'WV', 'VA', 'NC', 'SC', 'TN', 'AR', 'OK', 'LA', 'MS', 'AL', 'GA', 'FL']\n",
    "southern_states_in_all_states = ['TX']\n",
    "\n",
    "# Create a new column 'Region' to group states into regions\n",
    "wdf['Region'] = wdf['State'].apply(lambda x: 'Northern' if x in northern_states_in_all_states else ('Western' if x in western_satates_in_all_starts else ('Eastern' if x in eastern_states_in_all_states else 'Southern')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode to determine \"Recession\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Term' to days\n",
    "wdf[\"TermDays\"] = wdf['Term'] * 30\n",
    "\n",
    "# Calculate 'LoanDateEnd' by adding 'TermDays' to 'DisbursementDate'\n",
    "wdf[\"LoanDateEnd\"] = wdf['DisbursementDate'] + pd.to_timedelta(wdf['TermDays'], unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recession period\n",
    "recession_start = pd.to_datetime('2007-12-01')\n",
    "recession_end = pd.to_datetime('2009-06-30')\n",
    "\n",
    "# Create a new column 'Reccession' to indicate if the loan was disbursed during the recession period\n",
    "wdf['Recession'] = np.where((wdf['LoanDateEnd'] >= recession_start) & (wdf['LoanDateEnd'] <= recession_end), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_colum', None)\n",
    "pd.set_option('display.max_row', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode 'EmployeeLoanRatio' based on 'GrAppv' & 'NoEmp' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf['EmployeeLoanRatio'] = round(wdf['GrAppv'] / wdf['NoEmp'],2).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode 'StateRisk' based on State CHGOFF Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select States with ChgOff status\n",
    "chgoff_states = wdf.loc[wdf['MIS_Status'] == 'CHGOFF', ['MIS_Status', 'State']]\n",
    "\n",
    "# Group by State\n",
    "state_by_chrgoff_count = chgoff_states.groupby('State').size().reset_index(name='Count')\n",
    "\n",
    "# Sort Values by Count\n",
    "state_by_chrgoff_count = state_by_chrgoff_count.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Encode States based on Count\n",
    "state_by_chrgoff_count['StateRisk'] = state_by_chrgoff_count['Count'].apply(lambda x: \"High\" if x > 10000 else(\"Medium\" if 2000 < x < 10000 else \"Low\"))\n",
    "\n",
    "# Rank States based on Count\n",
    "high_risk_states = state_by_chrgoff_count.loc[state_by_chrgoff_count['StateRisk'] == 'High', 'State'].to_list()\n",
    "medium_risk_states = state_by_chrgoff_count.loc[state_by_chrgoff_count['StateRisk'] == 'Medium', 'State'].to_list()\n",
    "low_risk_states = state_by_chrgoff_count.loc[state_by_chrgoff_count['StateRisk'] == 'Low', 'State'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StateRisk column\n",
    "wdf['StateRisk'] = wdf['State'].apply(lambda x: \"High\" if x in high_risk_states else(\"Medium\" if x in medium_risk_states else \"Low\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoanNr_ChkDgt                 0\n",
       "Name                         14\n",
       "City                          0\n",
       "State                         0\n",
       "Zip                           0\n",
       "Bank                       1559\n",
       "BankState                  1566\n",
       "NAICS                         0\n",
       "ApprovalDate                  0\n",
       "ApprovalFY                    0\n",
       "Term                          0\n",
       "NoEmp                         0\n",
       "NewExist                   1170\n",
       "CreateJob                     0\n",
       "RetainedJob                   0\n",
       "FranchiseCode                 0\n",
       "UrbanRural               323167\n",
       "RevLineCr                277479\n",
       "LowDoc                        0\n",
       "ChgOffDate                    0\n",
       "DisbursementDate              0\n",
       "DisbursementGross             0\n",
       "BalanceGross                  0\n",
       "MIS_Status                 1736\n",
       "ChgOffPrinGr                  0\n",
       "GrAppv                        0\n",
       "SBA_Appv                      0\n",
       "NAICS_class_code              0\n",
       "Industry                      0\n",
       "FranchiseCode_Encoded         0\n",
       "RealEstate_Backed             0\n",
       "ApprovalDateYear              0\n",
       "ChgOffDateYear                0\n",
       "ApprovalDateMonth             0\n",
       "DisbursementDateYear          0\n",
       "Region                        0\n",
       "TermDays                      0\n",
       "LoanDateEnd                   0\n",
       "Recession                     0\n",
       "EmployeeLoanRatio             0\n",
       "StateRisk                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify target column with missing rows\n",
    "rows_with_missing_values = ['MIS_Status']\n",
    "\n",
    "# Filter dataset to only include rows without missing target values\n",
    "wdf = wdf[wdf[rows_with_missing_values].notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf.to_csv('cleaned_cat_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
