{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('.csv/cleaned_data.csv', index_col = 0)\n",
    "model_data = df.copy()\n",
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for iterative imputing\n",
    "randomforest_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_data.replace(np.inf, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_data['NewExist_Encoded'] = randomforest_data['NewExist'].map({1.0 : 1, 2.0: 2, np.nan: 0})\n",
    "randomforest_data['UrbanRural_Encoded'] = randomforest_data['UrbanRural'].map({1.0 : 1, 2.0: 2, 0.0: 0}).fillna(0).astype('int64')\n",
    "randomforest_data['MIS_Status_Encoded'] = randomforest_data['MIS_Status'].map({'CHGOFF': 0, 'PIF': 1})\n",
    "randomforest_data['RevLineCr_Encoded'] = randomforest_data['RevLineCr'].map({'N': 1, 'Y': 2}).fillna(0).astype('int64')\n",
    "randomforest_data['LowDoc_Encoded'] = randomforest_data['LowDoc'].map({'N': 0, 'Y': 1})\n",
    "randomforest_data['FranchiseCode_Encoded'] = randomforest_data['FranchiseCode_Encoded'].map({'No': 0, 'Yes': 1}).astype('int64')\n",
    "randomforest_data['RealEstate_Backed'] = randomforest_data['RealEstate_Backed'].map({'No': 0, 'Yes': 1}).astype('int64')\n",
    "randomforest_data['CreateJob_Encoded'] = randomforest_data['CreateJob'].apply(lambda x: 1 if x > 0 else 0)\n",
    "randomforest_data['RetainedJob_Encoded'] = randomforest_data['RetainedJob'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_data.loc[:, 'EmployeeLoanRatio'] = randomforest_data.apply(\n",
    "    lambda row: round(row['GrAppv']) if pd.isna(row['EmployeeLoanRatio']) else round(row['EmployeeLoanRatio']),\n",
    "    axis=1\n",
    ").astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_data.drop(labels=['LoanNr_ChkDgt', 'Name', 'City', 'Bank', 'BankState', 'TermDays', 'ApprovalDate', 'ApprovalFY', 'Zip', 'DisbursementDate', \n",
    "                      'DisbursementGross','NewExist', 'RetainedJob', 'LowDoc' ,'UrbanRural', 'RevLineCr', 'ChgOffDate',\n",
    "                      'BalanceGross', 'MIS_Status', 'ChgOffPrinGr', 'SBA_Appv', 'Industry', 'Recession',\n",
    "                       'ApprovalDateYear', 'ChgOffDateYear', 'ApprovalDateMonth', 'DisbursementDateYear',\n",
    "                       'LoanDateEnd'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot-Encode the categorical variables\n",
    "randomforest_data = pd.get_dummies(randomforest_data, columns=['State', 'Region', 'StateRisk']).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeladebayo/Documents/Simplon/brief_projects/loan_prediction/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into features and target\n",
    "X_rf = randomforest_data.drop(columns=['MIS_Status_Encoded'])\n",
    "y_rf = randomforest_data['MIS_Status_Encoded']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42, stratify=y_rf)\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['GrAppv', 'CreateJob', 'NAICS', 'Term', 'NoEmp', 'EmployeeLoanRatio']\n",
    "categorical_features = ['NAICS_class_code', 'FranchiseCode_Encoded', 'RealEstate_Backed', 'EmployeeLoanRatio', 'NewExist_Encoded',\n",
    "                        'UrbanRural_Encoded', 'RevLineCr_Encoded',\n",
    "                        'LowDoc_Encoded', 'CreateJob_Encoded', 'RetainedJob_Encoded',\n",
    "                        'State_AK', 'State_AL', 'State_AR', 'State_AZ', 'State_CA', 'State_CO',\n",
    "                        'State_CT', 'State_DC', 'State_DE', 'State_FL', 'State_GA', 'State_HI',\n",
    "                        'State_IA', 'State_ID', 'State_IL', 'State_IN', 'State_KS', 'State_KY',\n",
    "                        'State_LA', 'State_MA', 'State_MD', 'State_ME', 'State_MI', 'State_MN',\n",
    "                        'State_MO', 'State_MS', 'State_MT', 'State_NC', 'State_ND', 'State_NE',\n",
    "                        'State_NH', 'State_NJ', 'State_NM', 'State_NV', 'State_NY', 'State_OH',\n",
    "                        'State_OK', 'State_OR', 'State_PA', 'State_RI', 'State_SC', 'State_SD',\n",
    "                        'State_TN', 'State_TX', 'State_UT', 'State_VA', 'State_VT', 'State_WA',\n",
    "                        'State_WI', 'State_WV', 'State_WY', 'Region_Eastern', 'Region_Northern',\n",
    "                        'Region_Southern', 'Region_Western', 'StateRisk_High', 'StateRisk_Low',\n",
    "                        'StateRisk_Medium']\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ])\n",
    "\n",
    "# Build Pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    #('poly', PolynomialFeatures(degree=2)),\n",
    "    ('random', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# Set RandomSearch parameters\n",
    "params = {\"random__random_state\": [42],\n",
    "          \"random__n_jobs\": [7],\n",
    "          \"random__criterion\": ['gini','entropy', 'log_loss'],\n",
    "          \"random__n_estimators\": [900],\n",
    "          \"random__class_weight\": ['balanced_subsample'],\n",
    "          \"random__ccp_alpha\": [1.8],\n",
    "}\n",
    "\n",
    "# Set RandomSearchCV parameters\n",
    "rf_random_search = RandomizedSearchCV(model_pipeline, param_distributions=params, cv=5, random_state= 42, error_score='raise')\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameterd and score\n",
    "print(\"Best Params\", rf_random_search.best_estimator_)\n",
    "print(\"Best Score:\", rf_random_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
