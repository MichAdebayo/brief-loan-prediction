{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('.csv/cleaned_data.csv', index_col = 0)\n",
    "xgb_data = df.copy()\n",
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data.replace(np.inf, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data['NewExist_Encoded'] = xgb_data['NewExist'].map({1.0 : 1, 2.0: 2, np.nan: 0})\n",
    "xgb_data['UrbanRural_Encoded'] = xgb_data['UrbanRural'].map({1.0 : 1, 2.0: 2, 0.0: 0}).fillna(0).astype('int64')\n",
    "xgb_data['MIS_Status_Encoded'] = xgb_data['MIS_Status'].map({'CHGOFF': 0, 'PIF': 1})\n",
    "xgb_data['RevLineCr_Encoded'] = xgb_data['RevLineCr'].map({'N': 1, 'Y': 2}).fillna(0).astype('int64')\n",
    "xgb_data['LowDoc_Encoded'] = xgb_data['LowDoc'].map({'N': 0, 'Y': 1})\n",
    "xgb_data['FranchiseCode_Encoded'] = xgb_data['FranchiseCode_Encoded'].map({'No': 0, 'Yes': 1}).astype('int64')\n",
    "xgb_data['RealEstate_Backed'] = xgb_data['RealEstate_Backed'].map({'No': 0, 'Yes': 1}).astype('int64')\n",
    "xgb_data['CreateJob_Encoded'] = xgb_data['CreateJob'].apply(lambda x: 1 if x > 0 else 0)\n",
    "xgb_data['RetainedJob_Encoded'] = xgb_data['RetainedJob'].apply(lambda x: 1 if x > 0 else 0)\n",
    "xgb_data['State'] = xgb_data['State'].astype('category')\n",
    "xgb_data['StateRisk'] = xgb_data['StateRisk'].astype('category')\n",
    "xgb_data['Region'] = xgb_data['Region'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_data['NewExist_Encoded'] = xgb_data['NewExist'].map({1.0 : 1, 2.0: 2}, na_action='ignore')\n",
    "# xgb_data['UrbanRural_Encoded'] = xgb_data['UrbanRural'].map({1.0 : 1, 2.0: 2, 0.0: 0}, na_action='ignore')\n",
    "# xgb_data['MIS_Status_Encoded'] = xgb_data['MIS_Status'].map({'CHGOFF': 0, 'PIF': 1})\n",
    "# xgb_data['RevLineCr_Encoded'] = xgb_data['RevLineCr'].map({'N': 1, 'Y': 2}, na_action='ignore')\n",
    "# xgb_data['LowDoc_Encoded'] = xgb_data['LowDoc'].map({'N': 0, 'Y': 1})\n",
    "# xgb_data['FranchiseCode_Encoded'] = xgb_data['FranchiseCode_Encoded'].map({'No': 0, 'Yes': 1}).astype('int64')\n",
    "# xgb_data['RealEstate_Backed'] = xgb_data['RealEstate_Backed'].map({'No': 0, 'Yes': 1}).astype('int64')\n",
    "# xgb_data['CreateJob_Encoded'] = xgb_data['CreateJob'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# xgb_data['RetainedJob_Encoded'] = xgb_data['RetainedJob'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# xgb_data['State'] = xgb_data['State'].astype('category')\n",
    "# xgb_data['StateRisk'] = xgb_data['StateRisk'].astype('category')\n",
    "# xgb_data['Region'] = xgb_data['Region'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data.loc[:, 'EmployeeLoanRatio'] = xgb_data.apply(\n",
    "    lambda row: round(row['GrAppv']) if pd.isna(row['EmployeeLoanRatio']) else round(row['EmployeeLoanRatio']),\n",
    "    axis=1\n",
    ").astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data.drop(labels=['LoanNr_ChkDgt', 'Name', 'City', 'Bank', 'BankState', 'TermDays', 'ApprovalDate', 'ApprovalFY', 'Zip', 'DisbursementDate', \n",
    "                      'DisbursementGross','NewExist', 'RetainedJob', 'LowDoc' ,'UrbanRural', 'RevLineCr', 'ChgOffDate',\n",
    "                      'BalanceGross', 'MIS_Status', 'ChgOffPrinGr', 'SBA_Appv', 'Industry', 'RetainedJob_Encoded',\n",
    "                       'ApprovalDateYear', 'ChgOffDateYear', 'ApprovalDateMonth', 'DisbursementDateYear',\n",
    "                       'LoanDateEnd'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies\n",
    "dummy_cols = pd.get_dummies(xgb_data[['State', 'Region', 'StateRisk']])  \n",
    "\n",
    "# Convert dummies to int\n",
    "dummy_cols = dummy_cols.astype(int)  \n",
    "\n",
    "# Merge back to original DataFrame\n",
    "xgb_data = pd.concat([xgb_data, dummy_cols], axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'NAICS', 'Term', 'NoEmp', 'CreateJob', 'FranchiseCode',\n",
       "       'GrAppv', 'NAICS_class_code', 'FranchiseCode_Encoded',\n",
       "       'RealEstate_Backed', 'Region', 'Recession', 'EmployeeLoanRatio',\n",
       "       'StateRisk', 'NewExist_Encoded', 'UrbanRural_Encoded',\n",
       "       'MIS_Status_Encoded', 'RevLineCr_Encoded', 'LowDoc_Encoded',\n",
       "       'CreateJob_Encoded', 'RetainedJob_Encoded', 'State_AK', 'State_AL',\n",
       "       'State_AR', 'State_AZ', 'State_CA', 'State_CO', 'State_CT', 'State_DC',\n",
       "       'State_DE', 'State_FL', 'State_GA', 'State_HI', 'State_IA', 'State_ID',\n",
       "       'State_IL', 'State_IN', 'State_KS', 'State_KY', 'State_LA', 'State_MA',\n",
       "       'State_MD', 'State_ME', 'State_MI', 'State_MN', 'State_MO', 'State_MS',\n",
       "       'State_MT', 'State_NC', 'State_ND', 'State_NE', 'State_NH', 'State_NJ',\n",
       "       'State_NM', 'State_NV', 'State_NY', 'State_OH', 'State_OK', 'State_OR',\n",
       "       'State_PA', 'State_RI', 'State_SC', 'State_SD', 'State_TN', 'State_TX',\n",
       "       'State_UT', 'State_VA', 'State_VT', 'State_WA', 'State_WI', 'State_WV',\n",
       "       'State_WY', 'Region_Eastern', 'Region_Northern', 'Region_Southern',\n",
       "       'Region_Western', 'StateRisk_High', 'StateRisk_Low',\n",
       "       'StateRisk_Medium'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_data.drop(['State', 'Region', 'StateRisk'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_features = ['GrAppv', 'CreateJob', 'Term', 'NoEmp', 'NAICS', 'EmployeeLoanRatio', 'FranchiseCode',]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerics = scaler.fit_transform(xgb_data[numerical_features])\n",
    "\n",
    "xgb_data[numerical_features] = scaled_numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Define the target columns\n",
    "target_columns = ['MIS_Status_Encoded', 'State_AK', 'State_AL',\n",
    "       'State_AR', 'State_AZ', 'State_CA', 'State_CO', 'State_CT', 'State_DC',\n",
    "       'State_DE', 'State_FL', 'State_GA', 'State_HI', 'State_IA', 'State_ID',\n",
    "       'State_IL', 'State_IN', 'State_KS', 'State_KY', 'State_LA', 'State_MA',\n",
    "       'State_MD', 'State_ME', 'State_MI', 'State_MN', 'State_MO', 'State_MS',\n",
    "       'State_MT', 'State_NC', 'State_ND', 'State_NE', 'State_NH', 'State_NJ',\n",
    "       'State_NM', 'State_NV', 'State_NY', 'State_OH', 'State_OK', 'State_OR',\n",
    "       'State_PA', 'State_RI', 'State_SC', 'State_SD', 'State_TN', 'State_TX',\n",
    "       'State_UT', 'State_VA', 'State_VT', 'State_WA', 'State_WI', 'State_WV',\n",
    "       'State_WY', 'Region_Eastern', 'Region_Northern', 'Region_Southern',\n",
    "       'Region_Western', 'StateRisk_High', 'StateRisk_Low',\n",
    "       'StateRisk_Medium']\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = xgb_data.drop(columns=target_columns).reset_index(drop=True)  # Drop target and reset index\n",
    "y = xgb_data[target_columns].reset_index(drop=True)  # Store target separately and reset index\n",
    "\n",
    "# Apply PolynomialFeatures\n",
    "polyfit = PolynomialFeatures(degree=2) \n",
    "X_poly = polyfit.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame with feature names\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=polyfit.get_feature_names_out(X.columns))\n",
    "\n",
    "# Concatenate transformed features and target\n",
    "xgb_data_polyfit_df = pd.concat([X_poly_df, y], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features and target\n",
    "X = xgb_data.drop(columns=['MIS_Status_Encoded'])\n",
    "y = xgb_data['MIS_Status_Encoded']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeladebayo/Documents/Simplon/brief_projects/loan_prediction/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [13:32:44] WARNING: /Users/runner/work/xgboost/xgboost/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.95\n",
      "Best parameters saved to CSV successfully!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define model\n",
    "model = xgb.XGBClassifier(booster= 'gbtree', enable_categorical=True,\n",
    "                          device='cuda', objective='binary:logistic',\n",
    "                          eval_metric= 'logloss',\n",
    "                          subsample= 0.8,\n",
    "                          gamma= 4,\n",
    "                          colsample_bytree=0.7,\n",
    "                          max_depth= 25,\n",
    "                          reg_lambda= 0.1,\n",
    "                          reg_alpha= 10,\n",
    "                          n_estimators= 800,\n",
    "                          learning_rate=0.27777)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "\n",
    "print(\"Training Score:\", round(train_score, 2))\n",
    "\n",
    "# Store model parameters in a DataFrame\n",
    "best_xgb_params = model.get_params()  # Get model's hyperparameters\n",
    "best_xgb_params_df = pd.DataFrame([best_xgb_params])\n",
    "\n",
    "# Save to CSV\n",
    "best_xgb_params_df.to_csv(\"best_xgb_params.csv\", index=False)\n",
    "\n",
    "print(\"Best parameters saved to CSV successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m xgb_y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate the accuracy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m xgb_classification_report \u001b[38;5;241m=\u001b[39m classification_report(y_test, xgb_y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions\n",
    "xgb_y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "xgb_classification_report = classification_report(y_test, xgb_y_pred)\n",
    "\n",
    "print(xgb_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# model = xgb.XGBClassifier(booster='gbtree', enable_categorical=True,\n",
    "#                           device='cuda',\n",
    "#                           objective='binary:logistic')\n",
    "\n",
    "# # Define search space for hyperparameters\n",
    "# param_dist = {\n",
    "#     \"n_estimators\": np.arange(100, 501, 100),  # 100 to 1000, step 100\n",
    "#     \"max_depth\": np.arange(3, 16, 2),  # 3 to 15, step 2\n",
    "#     \"learning_rate\": np.linspace(0.01, 0.3, 5),  # 10 values between 0.01 and 0.3\n",
    "#     \"gamma\": np.linspace(0, 5, 4),  # 6 values between 0 and 5\n",
    "#     \"reg_lambda\": np.logspace(-3, 2, 4),  # Regularization term λ\n",
    "#     \"reg_alpha\": np.logspace(-3, 2, 4),  # Regularization term α\n",
    "# }\n",
    "\n",
    "# # Perform randomized search\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     model, param_distributions=param_dist, \n",
    "#     n_iter=5,  # Number of random parameter combinations to try\n",
    "#     scoring=\"accuracy\", \n",
    "#     cv=4,  # 5-fold cross-validation\n",
    "#     verbose=1, \n",
    "#     n_jobs=-1,  # Use all CPU cores\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Fit RandomizedSearchCV\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get best parameters\n",
    "# best_xgb_params = random_search.best_params_\n",
    "# best_xgb_params_df = pd.DataFrame([best_xgb_params])\n",
    "\n",
    "# # Save best parameters to CSV\n",
    "# best_xgb_params_df.to_csv(\"best_xgb_params.csv\", index=False)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best Parameters:\", best_xgb_params)\n",
    "# print(\"Best Score:\", round(random_search.best_score_, 2))\n",
    "# print(\"Best parameters saved to CSV successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# t_model = random_search.best_estimator_\n",
    "\n",
    "# # Make predictions\n",
    "# xgb_y_pred = t_model.predict(X_test)\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# xgb_classification_report = classification_report(y_test, xgb_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xgb_classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
